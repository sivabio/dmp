{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d7634b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17002, 8)\n",
      "    age  blood_glucose_level  HbA1c_level    bmi  hypertension  heart_disease  \\\n",
      "0  39.0                  200          6.8  41.59             0              0   \n",
      "1  55.0                  280          7.5  27.32             1              1   \n",
      "2  80.0                   80          4.8  22.84             1              0   \n",
      "3  43.0                  160          6.5  25.60             0              0   \n",
      "4  47.0                  158          6.2  27.32             0              0   \n",
      "\n",
      "   gender  group  \n",
      "0  Female      1  \n",
      "1    Male      1  \n",
      "2    Male      0  \n",
      "3  Female      0  \n",
      "4    Male      0  \n"
     ]
    }
   ],
   "source": [
    "# Ensure the filename matches the dataset\n",
    "import pandas as pd\n",
    "df_data = pd.read_csv(\"C:/Users/sivak/Envs/dj/djprojects/dmp/diabetes_prediction_dataset.csv\")\n",
    "print(df_data.shape)  # Should print\n",
    "print(df_data.head())  # Check the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3722a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17002.000000</td>\n",
       "      <td>17002.000000</td>\n",
       "      <td>17002.000000</td>\n",
       "      <td>17002.000000</td>\n",
       "      <td>17002.000000</td>\n",
       "      <td>17002.000000</td>\n",
       "      <td>17002.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.650848</td>\n",
       "      <td>163.733384</td>\n",
       "      <td>6.174368</td>\n",
       "      <td>29.423265</td>\n",
       "      <td>0.153805</td>\n",
       "      <td>0.090460</td>\n",
       "      <td>0.499941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.489825</td>\n",
       "      <td>56.758493</td>\n",
       "      <td>1.277234</td>\n",
       "      <td>7.461808</td>\n",
       "      <td>0.360773</td>\n",
       "      <td>0.286848</td>\n",
       "      <td>0.500015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>10.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>25.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>27.320000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>32.860000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>88.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  blood_glucose_level   HbA1c_level           bmi  \\\n",
       "count  17002.000000         17002.000000  17002.000000  17002.000000   \n",
       "mean      50.650848           163.733384      6.174368     29.423265   \n",
       "std       21.489825            56.758493      1.277234      7.461808   \n",
       "min        0.080000            80.000000      3.500000     10.860000   \n",
       "25%       36.000000           130.000000      5.700000     25.700000   \n",
       "50%       54.000000           155.000000      6.100000     27.320000   \n",
       "75%       67.000000           200.000000      6.600000     32.860000   \n",
       "max       80.000000           300.000000      9.000000     88.760000   \n",
       "\n",
       "       hypertension  heart_disease         group  \n",
       "count  17002.000000   17002.000000  17002.000000  \n",
       "mean       0.153805       0.090460      0.499941  \n",
       "std        0.360773       0.286848      0.500015  \n",
       "min        0.000000       0.000000      0.000000  \n",
       "25%        0.000000       0.000000      0.000000  \n",
       "50%        0.000000       0.000000      0.000000  \n",
       "75%        0.000000       0.000000      1.000000  \n",
       "max        1.000000       1.000000      1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b709154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender : object\n"
     ]
    }
   ],
   "source": [
    "text_columns = ['gender']\n",
    "for i in text_columns:\n",
    "  print(f\"{i} : {df_data[i].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53ad482e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = df_data.isnull().sum()\n",
    "missing[missing>0].sort_values(ascending=False).head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d4fcd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  blood_glucose_level  HbA1c_level    bmi  hypertension  heart_disease  \\\n",
      "0  39.0                  200          6.8  41.59             0              0   \n",
      "1  55.0                  280          7.5  27.32             1              1   \n",
      "2  80.0                   80          4.8  22.84             1              0   \n",
      "3  43.0                  160          6.5  25.60             0              0   \n",
      "4  47.0                  158          6.2  27.32             0              0   \n",
      "\n",
      "   gender  group  \n",
      "0  Female      1  \n",
      "1    Male      1  \n",
      "2    Male      0  \n",
      "3  Female      0  \n",
      "4    Male      0  \n"
     ]
    }
   ],
   "source": [
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45bea8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender :- ['Female' 'Male']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gender :- {df_data['gender'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ca9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['gender'] = df_data['gender'].map({'Male': 1, 'Female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7be4a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>gender</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>200</td>\n",
       "      <td>6.8</td>\n",
       "      <td>41.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>280</td>\n",
       "      <td>7.5</td>\n",
       "      <td>27.32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>80</td>\n",
       "      <td>4.8</td>\n",
       "      <td>22.84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.0</td>\n",
       "      <td>160</td>\n",
       "      <td>6.5</td>\n",
       "      <td>25.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.0</td>\n",
       "      <td>158</td>\n",
       "      <td>6.2</td>\n",
       "      <td>27.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  blood_glucose_level  HbA1c_level    bmi  hypertension  heart_disease  \\\n",
       "0  39.0                  200          6.8  41.59             0              0   \n",
       "1  55.0                  280          7.5  27.32             1              1   \n",
       "2  80.0                   80          4.8  22.84             1              0   \n",
       "3  43.0                  160          6.5  25.60             0              0   \n",
       "4  47.0                  158          6.2  27.32             0              0   \n",
       "\n",
       "   gender  group  \n",
       "0       0      1  \n",
       "1       1      1  \n",
       "2       1      0  \n",
       "3       0      0  \n",
       "4       1      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09fa0c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "group\n",
       "0    8502\n",
       "1    8500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02bf2291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.8200 - loss: 0.4257 - val_accuracy: 0.8895 - val_loss: 0.2466\n",
      "Epoch 2/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8779 - loss: 0.2658 - val_accuracy: 0.8902 - val_loss: 0.2427\n",
      "Epoch 3/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8781 - loss: 0.2645 - val_accuracy: 0.8914 - val_loss: 0.2392\n",
      "Epoch 4/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8822 - loss: 0.2618 - val_accuracy: 0.8938 - val_loss: 0.2359\n",
      "Epoch 5/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8794 - loss: 0.2520 - val_accuracy: 0.8957 - val_loss: 0.2298\n",
      "Epoch 6/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8853 - loss: 0.2451 - val_accuracy: 0.8949 - val_loss: 0.2241\n",
      "Epoch 7/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8886 - loss: 0.2427 - val_accuracy: 0.9008 - val_loss: 0.2203\n",
      "Epoch 8/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8920 - loss: 0.2300 - val_accuracy: 0.9000 - val_loss: 0.2156\n",
      "Epoch 9/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8946 - loss: 0.2220 - val_accuracy: 0.9032 - val_loss: 0.2105\n",
      "Epoch 10/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8991 - loss: 0.2226 - val_accuracy: 0.9055 - val_loss: 0.2062\n",
      "Epoch 11/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8952 - loss: 0.2186 - val_accuracy: 0.9067 - val_loss: 0.2017\n",
      "Epoch 12/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8975 - loss: 0.2175 - val_accuracy: 0.9051 - val_loss: 0.2011\n",
      "Epoch 13/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8974 - loss: 0.2092 - val_accuracy: 0.9071 - val_loss: 0.1989\n",
      "Epoch 14/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9048 - loss: 0.2085 - val_accuracy: 0.9087 - val_loss: 0.1975\n",
      "Epoch 15/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8960 - loss: 0.2155 - val_accuracy: 0.9114 - val_loss: 0.1942\n",
      "Epoch 16/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.2056 - val_accuracy: 0.9098 - val_loss: 0.1933\n",
      "Epoch 17/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9043 - loss: 0.2019 - val_accuracy: 0.9102 - val_loss: 0.1918\n",
      "Epoch 18/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9011 - loss: 0.2079 - val_accuracy: 0.9087 - val_loss: 0.1900\n",
      "Epoch 19/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9044 - loss: 0.2021 - val_accuracy: 0.9102 - val_loss: 0.1904\n",
      "Epoch 20/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9040 - loss: 0.1971 - val_accuracy: 0.9075 - val_loss: 0.1898\n",
      "Epoch 21/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9046 - loss: 0.2004 - val_accuracy: 0.9098 - val_loss: 0.1916\n",
      "Epoch 22/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9093 - loss: 0.1934 - val_accuracy: 0.9091 - val_loss: 0.1884\n",
      "Epoch 23/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.1941 - val_accuracy: 0.9102 - val_loss: 0.1879\n",
      "Epoch 24/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9008 - loss: 0.2018 - val_accuracy: 0.9087 - val_loss: 0.1871\n",
      "Epoch 25/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9001 - loss: 0.2016 - val_accuracy: 0.9102 - val_loss: 0.1902\n",
      "Epoch 26/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9082 - loss: 0.1938 - val_accuracy: 0.9075 - val_loss: 0.1863\n",
      "Epoch 27/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9077 - loss: 0.1949 - val_accuracy: 0.9079 - val_loss: 0.1864\n",
      "Epoch 28/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9056 - loss: 0.1975 - val_accuracy: 0.9098 - val_loss: 0.1876\n",
      "Epoch 29/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9085 - loss: 0.1867 - val_accuracy: 0.9114 - val_loss: 0.1875\n",
      "Epoch 30/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9030 - loss: 0.1956 - val_accuracy: 0.9071 - val_loss: 0.1875\n",
      "Epoch 31/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9064 - loss: 0.1943 - val_accuracy: 0.9083 - val_loss: 0.1865\n",
      "Epoch 32/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9103 - loss: 0.1936 - val_accuracy: 0.9083 - val_loss: 0.1871\n",
      "Epoch 33/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9032 - loss: 0.1955 - val_accuracy: 0.9106 - val_loss: 0.1886\n",
      "Epoch 34/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9082 - loss: 0.1972 - val_accuracy: 0.9075 - val_loss: 0.1863\n",
      "Epoch 35/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8985 - loss: 0.2004 - val_accuracy: 0.9083 - val_loss: 0.1864\n",
      "Epoch 36/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9077 - loss: 0.1928 - val_accuracy: 0.9075 - val_loss: 0.1862\n",
      "Epoch 37/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9057 - loss: 0.1935 - val_accuracy: 0.9098 - val_loss: 0.1860\n",
      "Epoch 38/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9078 - loss: 0.1959 - val_accuracy: 0.9075 - val_loss: 0.1868\n",
      "Epoch 39/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.1870 - val_accuracy: 0.9094 - val_loss: 0.1859\n",
      "Epoch 40/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9069 - loss: 0.1900 - val_accuracy: 0.9094 - val_loss: 0.1877\n",
      "Epoch 41/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9061 - loss: 0.1920 - val_accuracy: 0.9079 - val_loss: 0.1872\n",
      "Epoch 42/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9122 - loss: 0.1837 - val_accuracy: 0.9067 - val_loss: 0.1858\n",
      "Epoch 43/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9075 - loss: 0.1902 - val_accuracy: 0.9094 - val_loss: 0.1874\n",
      "Epoch 44/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9009 - loss: 0.1975 - val_accuracy: 0.9091 - val_loss: 0.1875\n",
      "Epoch 45/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9068 - loss: 0.1880 - val_accuracy: 0.9091 - val_loss: 0.1861\n",
      "Epoch 46/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9058 - loss: 0.1897 - val_accuracy: 0.9114 - val_loss: 0.1869\n",
      "Epoch 47/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.1889 - val_accuracy: 0.9071 - val_loss: 0.1864\n",
      "Epoch 48/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9084 - loss: 0.1896 - val_accuracy: 0.9102 - val_loss: 0.1873\n",
      "Epoch 49/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9076 - loss: 0.1879 - val_accuracy: 0.9087 - val_loss: 0.1849\n",
      "Epoch 50/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9056 - loss: 0.1937 - val_accuracy: 0.9083 - val_loss: 0.1882\n",
      "Epoch 51/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9070 - loss: 0.1898 - val_accuracy: 0.9114 - val_loss: 0.1865\n",
      "Epoch 52/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9077 - loss: 0.1911 - val_accuracy: 0.9106 - val_loss: 0.1860\n",
      "Epoch 53/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9107 - loss: 0.1894 - val_accuracy: 0.9094 - val_loss: 0.1874\n",
      "Epoch 54/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9012 - loss: 0.1958 - val_accuracy: 0.9087 - val_loss: 0.1855\n",
      "Epoch 55/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9056 - loss: 0.1940 - val_accuracy: 0.9102 - val_loss: 0.1855\n",
      "Epoch 56/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9074 - loss: 0.1932 - val_accuracy: 0.9087 - val_loss: 0.1861\n",
      "Epoch 57/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.1829 - val_accuracy: 0.9087 - val_loss: 0.1870\n",
      "Epoch 58/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9077 - loss: 0.1880 - val_accuracy: 0.9091 - val_loss: 0.1883\n",
      "Epoch 59/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9067 - loss: 0.1875 - val_accuracy: 0.9071 - val_loss: 0.1868\n",
      "Epoch 60/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9089 - loss: 0.1917 - val_accuracy: 0.9091 - val_loss: 0.1887\n",
      "Epoch 61/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9089 - loss: 0.1834 - val_accuracy: 0.9047 - val_loss: 0.1877\n",
      "Epoch 62/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9040 - loss: 0.1931 - val_accuracy: 0.9079 - val_loss: 0.1880\n",
      "Epoch 63/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9082 - loss: 0.1950 - val_accuracy: 0.9087 - val_loss: 0.1873\n",
      "Epoch 64/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9053 - loss: 0.1934 - val_accuracy: 0.9091 - val_loss: 0.1871\n",
      "Epoch 65/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9079 - loss: 0.1887 - val_accuracy: 0.9075 - val_loss: 0.1882\n",
      "Epoch 66/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9046 - loss: 0.1899 - val_accuracy: 0.9087 - val_loss: 0.1870\n",
      "Epoch 67/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9073 - loss: 0.1874 - val_accuracy: 0.9067 - val_loss: 0.1874\n",
      "Epoch 68/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9057 - loss: 0.1931 - val_accuracy: 0.9067 - val_loss: 0.1869\n",
      "Epoch 69/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9051 - loss: 0.1850 - val_accuracy: 0.9079 - val_loss: 0.1886\n",
      "Epoch 70/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9113 - loss: 0.1837 - val_accuracy: 0.9071 - val_loss: 0.1878\n",
      "Epoch 71/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9098 - loss: 0.1837 - val_accuracy: 0.9075 - val_loss: 0.1882\n",
      "Epoch 72/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9066 - loss: 0.1892 - val_accuracy: 0.9083 - val_loss: 0.1862\n",
      "Epoch 73/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9068 - loss: 0.1907 - val_accuracy: 0.9083 - val_loss: 0.1876\n",
      "Epoch 74/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9110 - loss: 0.1844 - val_accuracy: 0.9079 - val_loss: 0.1880\n",
      "Epoch 75/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9073 - loss: 0.1896 - val_accuracy: 0.9114 - val_loss: 0.1882\n",
      "Epoch 76/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.1883 - val_accuracy: 0.9102 - val_loss: 0.1889\n",
      "Epoch 77/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9073 - loss: 0.1867 - val_accuracy: 0.9094 - val_loss: 0.1876\n",
      "Epoch 78/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9073 - loss: 0.1857 - val_accuracy: 0.9087 - val_loss: 0.1890\n",
      "Epoch 79/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9145 - loss: 0.1820 - val_accuracy: 0.9083 - val_loss: 0.1878\n",
      "Epoch 80/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9105 - loss: 0.1830 - val_accuracy: 0.9098 - val_loss: 0.1886\n",
      "Epoch 81/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9047 - loss: 0.1917 - val_accuracy: 0.9091 - val_loss: 0.1879\n",
      "Epoch 82/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9084 - loss: 0.1841 - val_accuracy: 0.9094 - val_loss: 0.1874\n",
      "Epoch 83/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9106 - loss: 0.1846 - val_accuracy: 0.9067 - val_loss: 0.1893\n",
      "Epoch 84/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9043 - loss: 0.1871 - val_accuracy: 0.9094 - val_loss: 0.1883\n",
      "Epoch 85/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.1884 - val_accuracy: 0.9091 - val_loss: 0.1897\n",
      "Epoch 86/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9031 - loss: 0.1889 - val_accuracy: 0.9098 - val_loss: 0.1876\n",
      "Epoch 87/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9109 - loss: 0.1854 - val_accuracy: 0.9083 - val_loss: 0.1874\n",
      "Epoch 88/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9115 - loss: 0.1862 - val_accuracy: 0.9094 - val_loss: 0.1886\n",
      "Epoch 89/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9090 - loss: 0.1852 - val_accuracy: 0.9091 - val_loss: 0.1890\n",
      "Epoch 90/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9119 - loss: 0.1851 - val_accuracy: 0.9087 - val_loss: 0.1892\n",
      "Epoch 91/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9080 - loss: 0.1878 - val_accuracy: 0.9087 - val_loss: 0.1898\n",
      "Epoch 92/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9033 - loss: 0.1966 - val_accuracy: 0.9079 - val_loss: 0.1923\n",
      "Epoch 93/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9068 - loss: 0.1904 - val_accuracy: 0.9091 - val_loss: 0.1894\n",
      "Epoch 94/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9076 - loss: 0.1880 - val_accuracy: 0.9102 - val_loss: 0.1899\n",
      "Epoch 95/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9108 - loss: 0.1823 - val_accuracy: 0.9098 - val_loss: 0.1890\n",
      "Epoch 96/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9053 - loss: 0.1844 - val_accuracy: 0.9091 - val_loss: 0.1896\n",
      "Epoch 97/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9094 - loss: 0.1849 - val_accuracy: 0.9075 - val_loss: 0.1894\n",
      "Epoch 98/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9041 - loss: 0.1880 - val_accuracy: 0.9087 - val_loss: 0.1906\n",
      "Epoch 99/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.1903 - val_accuracy: 0.9075 - val_loss: 0.1901\n",
      "Epoch 100/100\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9060 - loss: 0.1890 - val_accuracy: 0.9087 - val_loss: 0.1893\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8976 - loss: 0.2040\n",
      "Test Accuracy: 0.90\n",
      "'X_train' shape: (12751, 7)\n",
      "'X_test' shape: (4251, 7)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 1. Generate dummy data\n",
    "X = df_data.drop(\"group\", axis=1)\n",
    "y = df_data[\"group\"]\n",
    "\n",
    "# 2. Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=25)\n",
    "\n",
    "# 3. Build the ANN model\n",
    "model = Sequential([\n",
    "    Input(shape=(7,)),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(units=1, activation='sigmoid')  # sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# 4. Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 5. Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# 6. Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "print(f\"'X_train' shape: {X_train.shape}\")\n",
    "print(f\"'X_test' shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fd10c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save TensorFlow model\n",
    "model.save(\"ann_model.h5\")\n",
    "\n",
    "# Save StandardScaler\n",
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2340cbb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,877</span> (30.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,877\u001b[0m (30.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,625</span> (10.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,625\u001b[0m (10.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,252</span> (20.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,252\u001b[0m (20.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
